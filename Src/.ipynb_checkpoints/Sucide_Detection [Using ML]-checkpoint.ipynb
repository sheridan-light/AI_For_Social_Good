{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../Datasets/combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>name</th>\n",
       "      <th>is_sucide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>We've been seeing a worrying increase in pro-s...</td>\n",
       "      <td>New wiki on how to avoid accidentally encourag...</td>\n",
       "      <td>t3_cz6nfd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>If you want to recognise an occasion, please d...</td>\n",
       "      <td>Reminder: Absolutely no activism of any kind i...</td>\n",
       "      <td>t3_d2370x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sleep just isn't sleep anymore, it's an escape.</td>\n",
       "      <td>t3_gosr7c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>I just want to go to sleep, and never wake up</td>\n",
       "      <td>Fuck me</td>\n",
       "      <td>t3_gomrql</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Seriously going through some existential stuff...</td>\n",
       "      <td>What is the point of living in this corrupt ce...</td>\n",
       "      <td>t3_gow0e9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit                                           selftext  \\\n",
       "0  SuicideWatch  We've been seeing a worrying increase in pro-s...   \n",
       "1  SuicideWatch  If you want to recognise an occasion, please d...   \n",
       "2  SuicideWatch                                                NaN   \n",
       "3  SuicideWatch      I just want to go to sleep, and never wake up   \n",
       "4  SuicideWatch  Seriously going through some existential stuff...   \n",
       "\n",
       "                                               title       name  is_sucide  \n",
       "0  New wiki on how to avoid accidentally encourag...  t3_cz6nfd          1  \n",
       "1  Reminder: Absolutely no activism of any kind i...  t3_d2370x          1  \n",
       "2    sleep just isn't sleep anymore, it's an escape.  t3_gosr7c          1  \n",
       "3                                            Fuck me  t3_gomrql          1  \n",
       "4  What is the point of living in this corrupt ce...  t3_gow0e9          1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1954 entries, 0 to 1953\n",
      "Data columns (total 5 columns):\n",
      "subreddit    1954 non-null object\n",
      "selftext     1871 non-null object\n",
      "title        1954 non-null object\n",
      "name         1954 non-null object\n",
      "is_sucide    1954 non-null int64\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 76.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit     0\n",
       "selftext     83\n",
       "title         0\n",
       "name          0\n",
       "is_sucide     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext'].fillna('no text',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(a):\n",
    "    x=re.sub('[^a-zA-Z]',' ',a)\n",
    "    x=x.lower()\n",
    "    text=nltk.word_tokenize(x)\n",
    "    text=[wordnet.lemmatize(word) for word in text if word not in stopwords.words('english')]\n",
    "    text=' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext']=df['selftext'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>name</th>\n",
       "      <th>is_sucide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>seeing worrying increase pro suicide content s...</td>\n",
       "      <td>New wiki on how to avoid accidentally encourag...</td>\n",
       "      <td>t3_cz6nfd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>want recognise occasion please offering extra ...</td>\n",
       "      <td>Reminder: Absolutely no activism of any kind i...</td>\n",
       "      <td>t3_d2370x</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>text</td>\n",
       "      <td>sleep just isn't sleep anymore, it's an escape.</td>\n",
       "      <td>t3_gosr7c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>want go sleep never wake</td>\n",
       "      <td>Fuck me</td>\n",
       "      <td>t3_gomrql</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>seriously going existential stuff live society...</td>\n",
       "      <td>What is the point of living in this corrupt ce...</td>\n",
       "      <td>t3_gow0e9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit                                           selftext  \\\n",
       "0  SuicideWatch  seeing worrying increase pro suicide content s...   \n",
       "1  SuicideWatch  want recognise occasion please offering extra ...   \n",
       "2  SuicideWatch                                               text   \n",
       "3  SuicideWatch                           want go sleep never wake   \n",
       "4  SuicideWatch  seriously going existential stuff live society...   \n",
       "\n",
       "                                               title       name  is_sucide  \n",
       "0  New wiki on how to avoid accidentally encourag...  t3_cz6nfd          1  \n",
       "1  Reminder: Absolutely no activism of any kind i...  t3_d2370x          1  \n",
       "2    sleep just isn't sleep anymore, it's an escape.  t3_gosr7c          1  \n",
       "3                                            Fuck me  t3_gomrql          1  \n",
       "4  What is the point of living in this corrupt ce...  t3_gow0e9          1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit rain wet cold demon head fight gold watch tiny wet droplet fall wind guide shove rain fall pitter patter hit ground splatter oh wish could matter little anyone care let set free people tell worth thing keeping gravity tie earth evil thought constantly churning people tell need go school keep learning focus feel hopeless always distracted others reacted whirling hurricane inside brain present everlasting pain breath breath thinking death one day might commit one day might quit everyday hide behind mask hoping someone might ask hey okay oh mark leg arm well self harm society driven u finally see made walk open pleading silence everyone seems ignore thinking others give guidance sit rain wet cold demon head fight gold'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['selftext'][25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding With Bag Of Words and TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect1=CountVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect2=TfidfVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1=vect1.fit_transform(df['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2=vect2.fit_transform(df['selftext'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Accuracy with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(mat1,df['is_sucide'],random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=ShuffleSplit(n_splits=5,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62619808, 0.6485623 , 0.62619808, 0.63578275, 0.5942492 ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(),x_train,y_train,cv=cv,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68370607, 0.67731629, 0.63897764, 0.63897764, 0.59744409])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(MultinomialNB(),x_train,y_train,cv=cv,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63258786, 0.7028754 , 0.65814696, 0.66453674, 0.62300319])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(XGBClassifier(),x_train,y_train,cv=cv,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Accuracy With IFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1,x_test1,y_train1,y_test1=train_test_split(mat2,df['is_sucide'],random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6485623 , 0.63897764, 0.66773163, 0.61341853, 0.58785942])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(),x_train1,y_train1,cv=cv,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61661342, 0.62300319, 0.63897764, 0.65495208, 0.62619808])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(MultinomialNB(),x_train1,y_train1,cv=cv,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66453674, 0.68051118, 0.67092652, 0.64536741, 0.63258786])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(XGBClassifier(),x_train1,y_train1,cv=cv,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST with TFIDF Vectorizer Gives a good Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128,  60],\n",
       "       [ 90, 113]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63       188\n",
      "           1       0.65      0.56      0.60       203\n",
      "\n",
      "    accuracy                           0.62       391\n",
      "   macro avg       0.62      0.62      0.62       391\n",
      "weighted avg       0.62      0.62      0.62       391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting With New Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Depression Thought\n",
    "text1='''I don't know, it's like this unexplainable feeling. \n",
    "Like this physical feeling in my heart that pulsates throughout my whole being. \n",
    "Whenever I hear happy music or watch a cheesy movie where everybody's happy I just can't help but feel sad. \n",
    "Same thing if I see something from when I was a kid or something similar. \n",
    "I'm thinking the root of it may be I've felt like I've missed out on life or didn't make the most of it? \n",
    "I don't know. I'm just hoping it's not just me.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=vect2.transform([text1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression\n"
     ]
    }
   ],
   "source": [
    "pr=model.predict(x)\n",
    "if pr[0]==0:\n",
    "    print(\"Depression\")\n",
    "else:\n",
    "    print(\"Sucide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sucide Thought\n",
    "text2=''' It's been a year. An entire fucking year that I gave myself another chance. \n",
    "Or more like gave him another chance. Last year in October, I came close to killing myself. \n",
    "I had thought that nothing would ever get better and that there was absolutely no point living in a life that was FOR SURE never going to get better.\n",
    "Yet, I gave God another chance. That morning, a pack of coyotes howled during the sunset as the last song in my playlist of songs I want played in my funeral had ended.\n",
    "After hearing the coyotes, I thought it was a sign. A sign that God would make it better. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=vect2.transform([text2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucide\n"
     ]
    }
   ],
   "source": [
    "pr=model.predict(x)\n",
    "if pr[0]==0:\n",
    "    print(\"Depression\")\n",
    "else:\n",
    "    print(\"Sucide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_vectorizer.pkl','wb') as f:\n",
    "    pickle.dump(vect2,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgb.pkl','wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "* Model achived an highest accuracy of 62% which is less than accuracy achived by LSTM i.e (66.64%)\n",
    "* It Predicted the output correctly, but model accuracy needs to be improved\n",
    "* Accuracy can be improved by adding more text and cleaning the csv file properly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
